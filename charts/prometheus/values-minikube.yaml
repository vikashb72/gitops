env:
  EVT: minikube

kube-prometheus-stack:
  namespaceOverride: "monitoring"
  # https://raw.githubusercontent.com/prometheus-community/helm-charts/refs/heads/main/charts/kube-prometheus-stack/values.yaml
  crds:
    enabled: true
    upgradeJob:
      enabled: false
      forceConflicts: false
      serviceAccount:
        create: true
  ## custom Rules to override "for" and "severity" in defaultRules
  customRules: {}
    # AlertmanagerFailedReload:
    #   for: 3m
    # AlertmanagerMembersInconsistent:
    #   for: 5m
    #   severity: "warning"
  ## Create default rules for monitoring the cluster
  defaultRules:
    create: true
    rules:
      alertmanager: true
      etcd: false   # looking for kube-etcd 
      configReloaders: true
      general: true
      k8sContainerCpuUsageSecondsTotal: true
      k8sContainerMemoryCache: true
      k8sContainerMemoryRss: true
      k8sContainerMemorySwap: true
      k8sContainerResource: true
      k8sContainerMemoryWorkingSetBytes: true
      k8sPodOwner: true
      kubeApiserverAvailability: true
      kubeApiserverBurnrate: true
      kubeApiserverHistogram: true
      kubeApiserverSlos: true
      kubeControllerManager: true
      kubelet: true
      kubeProxy: true
      kubePrometheusGeneral: true
      kubePrometheusNodeRecording: true
      kubernetesApps: true
      kubernetesResources: true
      kubernetesStorage: true
      kubernetesSystem: true
      kubeSchedulerAlerting: true
      kubeSchedulerRecording: true
      kubeStateMetrics: true
      network: true
      node: true
      nodeExporterAlerting: true
      nodeExporterRecording: true
      prometheus: true
      prometheusOperator: true
      windows: false
    ## Labels for default rules
    labels: {}
    ## Annotations for default rules
    annotations: {}
    ## Disabled PrometheusRule alerts
    disabled: {}
    # KubeAPIDown: true
    # NodeRAIDDegraded: true
  ## Provide custom recording or alerting rules to be deployed into the cluster.
  ##
  additionalPrometheusRulesMap: {}
  #  rule-name:
  #    groups:
  #    - name: my_group
  #      rules:
  #      - record: my_record
  #        expr: 100 * my_record
  global:
    rbac:
      create: true
      createAggregateClusterRoles: true
  windowsMonitoring:
    ## Deploys the windows-exporter and Windows-specific dashboards and rules (job name must be 'windows-exporter')
    enabled: false
  prometheus-windows-exporter:
    prometheus:
      monitor:
        enabled: false
  alertmanager:
    enabled: true
    annotations: {}
    apiVersion: v2
    config:
      global:
        resolve_timeout: 5m
      inhibit_rules:
        - source_matchers:
            - 'severity = critical'
          target_matchers:
            - 'severity =~ warning|info'
          equal:
            - 'namespace'
            - 'alertname'
        - source_matchers:
            - 'severity = warning'
          target_matchers:
            - 'severity = info'
          equal:
            - 'namespace'
            - 'alertname'
        - source_matchers:
            - 'alertname = InfoInhibitor'
          target_matchers:
            - 'severity = info'
          equal:
            - 'namespace'
        - target_matchers:
            - 'alertname = InfoInhibitor'
      route:
        group_by: ['namespace']
        group_wait: 30s
        group_interval: 5m
        repeat_interval: 12h
        receiver: "email-alert"
        routes:
          - receiver: "null"
            match:
              alertname: "Watchdog"
          - receiver: "email-alert"
            continue: true
      receivers:
        - name: "null"
        - name: "email-alert"
          email_configs:
            - to: "vikashb@home.where-ever.za.net"
              from: "monitor@minikube.where-ever.net"
              #smarthost: "desktop.home.where-ever.za.net:587"
              smarthost: "odroid-dlna.home.where-ever.za.net:25"
              #auth_username: "vmail"
              #auth_password_file: /etc/alertmanager/secrets/GF_SMTP_PASSWORD
              #auth_password:
              require_tls: false
              send_resolved: true
        # https://prometheus.io/docs/alerting/latest/configuration/#email_config
        #- name: "ms-teams"
        #  msteams_config:
        #    send_resolved: true
        #    webhook_url_file: /etc/alertmanager/secrets/GF_MS_TEAMS_URL
        #- name: "ms-teams-v2"
        #  msteamsv2_config:
        #    send_resolved: true
        #    webhook_url_file: /etc/alertmanager/secrets/GF_MS_TEAMS_URL
      templates:
        - '/etc/alertmanager/config/*.tmpl'
    ## Configuration for Alertmanager service
    serviceMonitor:
      selfMonitor: true
    alertmanagerSpec:
      persistentVolumeClaimRetentionPolicy:
        whenDeleted: Retain
        whenScaled: Retain
      storage:
        volumeClaimTemplate:
          spec:
            storageClassName: nfs-client
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 10Gi
      volumes:
        - name: smtp-config
          secret:
            secretName: smtp-config
      volumeMounts:
        - name: smtp-config
          mountPath: /etc/alertmanager/secrets
          readOnly: true
    secret:
      annotations: {}
    service:
      type: LoadBalancer
      loadBalancerIP: 192.168.49.232
  grafana:
    namespaceOverride: "monitoring"
    enabled: true
    defaultDashboardsEditable: true
    smtp:
      enabled: true
      existingSecret: "smtp-config"
      passwordKey: "GF_SMTP_PASSWORD"
      userKey: "GF_SMTP_USER"
    grafana.ini:
      #log:
      #  level: debug
      unified_alerting:
        enabled: true
      smtp:
        enabled: true
        host: desktop.home.where-ever.za.net:587
        startTLS_policy: "MandatoryStartTLS"
        from_address: monitor@minikube.where-ever.net
        skip_verify: true # for minikube
    notifiers:
      notifiers.yaml:
        notifiers:
          - name: alertmanager-operated
            type: prometheus-alertmanager
            uid: alertmanager-operated
            org_id: 1
            is_default: true
            settings:
              url: http://alertmanager-operated:9093/
              #basicAuthPassword: 
              #basicAuthUser: admin
          #- name: email-notifier
          #  type: email
          #  uid: email-notifier
          #  org_id: 1
          #  is_default: false
          #  settings:
          #    addresses: vikashb@home.where-ever.za.net
    alerting:
      policies.yaml:
        apiVersion: 1
        policies:
            - orgId: 1
              receiver: alertmanager-operated
              #receiver: default-notification-email
              group_by:
                - grafana_folder
                - alertname
      contactpoints.yaml:
        secret:
          apiVersion: 1
          contactPoints:
            - orgId: 1
              name: alertmanager-operated
              receivers:
                - uid: alertmanager-operated
                  type: prometheus-alertmanager
                  settings:
                    #basicAuthPassword: 
                    #basicAuthUser: admin
                    url: http://alertmanager-operated:9093/
                  disableResolveMessage: false
            #- orgId: 1
            #  name: default-notification-email
            #  receivers:
            #    - uid: default-notification-email
            #      type: email
            #      settings:
            #        addresses: vikashb@home.where-ever.za.net
            #        singleEmail: false
            #      disableResolveMessage: false
            #- orgId: 1
            #  name: ms-teams-channel
            #  receivers:
            #    - uid: ms-teams-channel
            #      type: teams
            #      settings:
            #        url: https://localhost/
            #      disableResolveMessage: false
    initChownData:
      enabled: false
    serviceMonitor:
      enabled: true
      targetLabels:
        - prometheus

    adminUser: admin
    adminPassword: ""
    #admin:
    #  existingSecret: "grafana-admin-credentials"
    #  userKey: GF_SECURITY_ADMIN_USER
    #  passwordKey: GF_SECURITY_ADMIN_PASSWORD
    persistence:
      enabled: true
      type: pvc
      storageClassName: nfs-client
      accessModes:
        - ReadWriteOnce
      size: 10Gi
      finalizers:
        - kubernetes.io/pvc-protection
      inMemory:
        enabled: false
      lookupVolumeName: true
    sidecar:
      dashboards:
        enabled: true
        label: grafana_dashboard
        labelValue: "1"
        # Allow discovery in all namespaces for dashboards
        searchNamespace: ALL
  
        # Support for new table panels, when enabled grafana auto migrates the old table panels to newer table panels
        enableNewTablePanelSyntax: false
      datasources:
        enabled: true
        defaultDatasourceEnabled: true
        isDefaultDatasource: true
  
        name: Prometheus
        uid: prometheus
        exemplarTraceIdDestinations: {}
          # datasourceUid: Jaeger
          # traceIdLabelName: trace_id
          # urlDisplayLabel: View traces
        alertmanager:
          enabled: true
          name: Alertmanager
          uid: alertmanager
          handleGrafanaManagedAlerts: false
          implementation: prometheus
    service:
      enabled: true
      type: LoadBalancer
      loadBalancerIP: 192.168.49.231
    serviceMonitor:
      enabled: true
    plugins:
      - grafana-piechart-panel
      - macropower-analytics-panel
      - azure-monitor-app
      - digrich-bubblechart-panel
      - golioth-websocket-datasource
      - snuids-trend-panel
      - serrrios-statusoverview-panel
      - innius-grpc-datasource
      - novatec-sdg-panel
      - integrationmatters-comparison-panel
      ## You can also use other plugin download URL, as long as they are valid zip files,
      ## and specify the name of the plugin after the semicolon. Like this:
      # - https://grafana.com/api/plugins/marcusolsson-json-datasource/versions/1.3.2/download;marcusolsson-json-datasource
    #dashboards:
    #  default:
    #    # https://grafana.com/grafana/dashboards/2-prometheus-stats/
    #    prometheus-stats:
    #      gnetId: 2
    #      revision: 2
    #      datasource: Prometheus
    #    # https://grafana.com/grafana/dashboards/11835-redis-dashboard-for-prometheus-redis-exporter-helm-stable-redis-ha/
    #    redis-exporter:
    #      gnetId: 11835
    #      revision: 1
    #      datasource: Prometheus
    #    # https://grafana.com/grafana/dashboards/14699-kubernetes-status/
    #    kubernetes-status:
    #      gnetId: 14699
    #      revision: 2
    #      datasource: Prometheus
    #    #
    #    # TO TEST
    #    #
    #    # https://grafana.com/grafana/dashboards/14584-argocd/
    #    argocd:
    #      gnetId: 14584
    #      revision: 1
    #      datasource: Prometheus
    #    ## https://grafana.com/grafana/dashboards/11001-cert-manager/
    #    #cert-manager:
    #    #  gnetId: 11001
    #    #  revision: 1
    #    #  datasource: Prometheus
    #    ##keycloak-metrics:
    #    ##  gnetId: 10441
    #    ##  revision: 2
    #    ##  datasource: Prometheus
    #    ## https://grafana.com/grafana/dashboards/7645-istio-control-plane-dashboard/
    #    ##itio-control-plane:
    #    ##  gnetId: 7645
    #    ##  revision: 240
    #    ##  datasource: Prometheus
    #    ## https://grafana.com/grafana/dashboards/1860-node-exporter-full/
    # I have no idea why this breaks
    #envValueFrom:
    #  GF_SMTP_ENABLED:
    #    name: grafana-smtp-config
    #    key: GF_SMTP_ENABLED
    #  GF_SMTP_HOST:
    #    name: grafana-smtp-config
    #    key: GF_SMTP_HOST
    #  GF_SMTP_USER:
    #    name: grafana-smtp-config
    #    key: GF_SMTP_USER
    #  GF_SMTP_PASSWORD:
    #    name: grafana-smtp-config
    #    key: GF_SMTP_PASSWORD
    #  GF_SMTP_FROM_ADDRESS:
    #    name: grafana-smtp-config
    #    key: GF_SMTP_FROM_ADDRESS
    #  GF_SMTP_STARTTLS_POLICY:
    #    name: grafana-smtp-config
    #    key: GF_SMTP_STARTTLS_POLICY
  kubernetesServiceMonitors:
    enabled: true
  kubeApiServer:
    enabled: true
    tlsConfig:
      serverName: kubernetes
      insecureSkipVerify: false
  kubelet:
    enabled: true
    namespace: kube-system
    serviceMonitor:
      kubelet: true
  kubeControllerManager:
    enabled: true
    service:
      enabled: true
    serviceMonitor:
      enabled: true
  coreDns:
    enabled: true
    service:
      enabled: true
      ipDualStack:
        enabled: false
    serviceMonitor:
      enabled: true
  kubeDns:
    enabled: false
    service:
      ipDualStack:
        enabled: false
  kubeEtcd:
    enabled: true
    service:
      enabled: true
      ipDualStack:
        enabled: false
    serviceMonitor:
      enabled: true
  kubeScheduler:
    enabled: true
    service:
      enabled: true
      ipDualStack:
        enabled: false
    serviceMonitor:
      enabled: true
  kubeProxy:
    enabled: true
    service:
      enabled: true
      ipDualStack:
        enabled: false
    serviceMonitor:
      enabled: true
  kubeStateMetrics:
    enabled: true
  kube-state-metrics:
    #namespaceOverride: "monitoring"
    rbac:
      create: true
    prometheusScrape: false
    prometheus:
      monitor:
        enabled: true
    selfMonitor:
      enabled: false
  nodeExporter:
    enabled: true
    operatingSystems:
      linux:
        enabled: true
      aix:
        enabled: false
      darwin:
        enabled: false
  prometheus-node-exporter:
    #namespaceOverride: "monitoring"
    prometheus:
      monitor:
        enabled: true
  prometheusOperator:
    enabled: true
    tls:
      enabled: true
    admissionWebhooks:
      certManager:
        enabled: false
    networkPolicy:
      enabled: false
    serviceAccount:
      create: true
    ##
    service:
      ipDualStack:
        enabled: false
      type: ClusterIP
    kubeletService:
      enabled: true
      namespace: kube-system
    serviceMonitor:
      selfMonitor: true
    dnsConfig: {}
      # nameservers:
      #   - 1.2.3.4
      # searches:
      #   - ns1.svc.cluster-domain.example
      #   - my.dns.search.suffix
    # Enable vertical pod autoscaler support for prometheus-operator
    verticalPodAutoscaler:
      enabled: false
    prometheusConfigReloader:
      enableProbe: false
  prometheus:
    enabled: true
    networkPolicy:
      enabled: false
    serviceAccount:
      create: true
    service:
      type: LoadBalancer
      loadBalancerIP: 192.168.49.227
      ipDualStack:
        enabled: false
    serviceMonitor:
      selfMonitor: true
    prometheusSpec:
      persistentVolumeClaimRetentionPolicy: {}
      storageSpec:
        volumeClaimTemplate:
          spec:
            storageClassName: nfs-client
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 10Gi
    serviceMonitor:
      selfMonitor: true
##

#20250220#prometheus:
#20250220#  rbac:
#20250220#    create: true
#20250220#  serviceAccounts:
#20250220#    server:
#20250220#      create: true
#20250220#  server:
#20250220#    name: server
#20250220#    enableServiceLinks: true
#20250220#    extraFlags:
#20250220#      - web.enable-lifecycle
#20250220#    global:
#20250220#      scrape_interval: 1m
#20250220#      scrape_timeout: 10s
#20250220#      evaluation_interval: 1m
#20250220#    persistentVolume:
#20250220#      enabled: true
#20250220#      accessModes:
#20250220#        - ReadWriteOnce
#20250220#      mountPath: /data
#20250220#      size: 5Gi
#20250220#      storageClass: nfs-client
#20250220#    service:
#20250220#      enabled: true
#20250220#      type: LoadBalancer
#20250220#      loadBalancerIP: 192.168.49.227
#20250220#  prometheus-pushgateway:
#20250220#    enable: true
#20250220#
#20250220#  extraScrapeConfigs: ""
#20250220#    # - job_name: 'prometheus-blackbox-exporter'
#20250220#    #   metrics_path: /probe
#20250220#    #   params:
#20250220#    #     module: [http_2xx]
#20250220#    #   static_configs:
#20250220#    #     - targets:
#20250220#    #       - https://example.com
#20250220#    #   relabel_configs:
#20250220#    #     - source_labels: [__address__]
#20250220#    #       target_label: __param_target
#20250220#    #     - source_labels: [__param_target]
#20250220#    #       target_label: instance
#20250220#    #     - target_label: __address__
#20250220#    #       replacement: prometheus-blackbox-exporter:9115
#20250220
