oauth2-proxy:
  config:
    # Add config annotations
    annotations: {}
    existingSecret: "oidc-secrets"
    # The name of the cookie that oauth2-proxy will create
    # If left empty, it will default to the release name
    cookieName: ""
    configFile: |-
      user_id_claim = "sub"
      redirect_url = "http://127.0.0.1:80/oauth2/callback"
      email_domains = [ "*" ]
      upstreams = [ "file:///dev/null" ]
      pass_access_token = true
      cookie_secure = false # localdevonly
      http_address = "127.0.0.1:80" #localdev only
    # Custom configuration file: oauth2_proxy.cfg
    # configFile: |-
    #   pass_basic_auth = false
    #   pass_access_token = true
    # Use an existing config map (see configmap.yaml for required fields)
    # Example:
    # existingConfig: config
  
  alphaConfig:
    enabled: false
  
  # Set a custom containerPort if required.
  # This will default to 4180 if this value is not set and the httpScheme set to http
  # This will default to 4443 if this value is not set and the httpScheme set to https
  # containerPort: 4180
  
  extraArgs: {}
  #extraEnv: []
  extraEnv:
    - name: OAUTH2_PROXY_PROVIDER
      value: oidc
    - name: OAUTH2_PROXY_HTTP_ADDRESS
      value: "0.0.0.0:80"
    - name: OAUTH2_PROXY_OIDC_ISSUER_URL
      value: "https://zitadel.minikube.where-ever.net"
    #- name: OAUTH2_PROXY_LOGIN_URL
    #  value: https://authentik.minikube.where-ever.net/application/o/oauth2-proxy/
    #- name: OAUTH2_PROXY_REDEEM_URL
    #  value: https://authentik.minikube.where-ever.net/application/o/oauth2-proxy/
    #- name: OAUTH2_PROXY_VALIDATE_URL
    #  value: https://authentik.minikube.where-ever.net/application/o/userinfo/
    #- name: AUTH2_PROXY_OIDC_JWKS_URL
    #  value: https://authentik.minikube.where-ever.net/application/o/oauth2-proxy/jwks/
    #- name: OAUTH2_PROXY_OIDC_JWKS_URL
    #  value: https://authentik.minikube.where-ever.net/application/o/oauth2-proxy/jwks/
    #OAUTH2_PROXY_PASS_HOST_HEADER: false
    #OAUTH2_PROXY_COOKIE_SECURE: false
    #OAUTH2_PROXY_SCOPE: "openid profile email"
    #OAUTH2_PROXY_COOKIE_REFRESH: 5m
    #OAUTH2_PROXY_EMAIL_DOMAINS: '*'
    #OAUTH2_PROXY_INSECURE_OIDC_ALLOW_UNVERIFIED_EMAIL: 'true'
    #OAUTH2_PROXY_PROVIDER_DISPLAY_NAME: Authentik
    #OAUTH2_PROXY_SKIP_OIDC_DISCOVERY: 'true'
    #OAUTH2_PROXY_SKIP_PROVIDER_BUTTON: 'true'
    #OAUTH2_PROXY_SKIP_JWT_BEARER_TOKENS: 'true'
    #OAUTH2_PROXY_PASS_ACCESS_TOKEN: 'true'
  
  envFrom: []
  # Load environment variables from a ConfigMap(s) and/or Secret(s)
  # that already exists (created and managed by you).
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#configure-all-key-value-pairs-in-a-configmap-as-container-environment-variables
  #
  # PS: Changes in these ConfigMaps or Secrets will not be automatically
  #     detected and you must manually restart the relevant Pods after changes.
  #
  #  - configMapRef:
  #      name: special-config
  #  - secretRef:
  #      name: special-config-secret
  
  # -- Custom labels to add into metadata
  customLabels: {}
  
  # To authorize individual email addresses
  # That is part of extraArgs but since this needs special treatment we need to do a separate section
  authenticatedEmailsFile:
    enabled: false
    # Defines how the email addresses file will be projected, via a configmap or secret
    persistence: configmap
    # template is the name of the configmap what contains the email user list but has been configured without this chart.
    # It's a simpler way to maintain only one configmap (user list) instead changing it for each oauth2-proxy service.
    # Be aware the value name in the extern config map in data needs to be named to "restricted_user_access" or to the
    # provided value in restrictedUserAccessKey field.
    template: ""
    # The configmap/secret key under which the list of email access is stored
    # Defaults to "restricted_user_access" if not filled-in, but can be overridden to allow flexibility
    restrictedUserAccessKey: ""
    # One email per line
    # example:
    # restricted_access: |-
    #   name1@domain
    #   name2@domain
    # If you override the config with restricted_access it will configure a user list within this chart what takes care of the
    # config map resource.
    restricted_access: ""
    annotations: {}
    # helm.sh/resource-policy: keep
  
  service:
    type: ClusterIP
    # when service.type is ClusterIP ...
    # loadBalancerIP: 198.51.100.40
    # loadBalancerSourceRanges: 203.0.113.0/24
  
  ## Create or use ServiceAccount
  serviceAccount:
    ## Specifies whether a ServiceAccount should be created
    enabled: true
    ## The name of the ServiceAccount to use.
    ## If not set and create is true, a name is generated using the fullname template
    name:
    automountServiceAccountToken: true
    annotations: {}
  
  ingress:
    enabled: false
  
  resources: {}
    # limits:
    #   cpu: 100m
    #   memory: 300Mi
    # requests:
    #   cpu: 100m
    #   memory: 300Mi
  
  extraVolumes:
    - name: own-ca-bundle
      configMap:
        name: own-ca-bundle
        defaultMode: 0644
        optional: false
        items:
          - key: own-ca-bundle.pem
            path: ca-certificates.crt

  extraVolumeMounts:
    - mountPath: /etc/ssl/certs/
      name: own-ca-bundle
      readOnly: true
  
  # Additional containers to be added to the pod.
  extraContainers: []
    #  - name: my-sidecar
    #    image: nginx:latest
  
  # Additional Init containers to be added to the pod.
  extraInitContainers: []
    #  - name: wait-for-idp
    #    image: my-idp-wait:latest
    #    command:
    #    - sh
    #    - -c
    #    - wait-for-idp.sh
  
  priorityClassName: ""
  
  # hostAliases is a list of aliases to be added to /etc/hosts for network name resolution
  hostAliases: []
  # - ip: "10.xxx.xxx.xxx"
  #   hostnames:
  #     - "auth.example.com"
  # - ip: 127.0.0.1
  #   hostnames:
  #     - chart-example.local
  #     - example.local
  
  # [TopologySpreadConstraints](https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/) configuration.
  # Ref: https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling
  # topologySpreadConstraints: []
  
  # Affinity for pod assignment
  # Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  # affinity: {}
  
  # Tolerations for pod assignment
  # Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []
  
  # Node labels for pod assignment
  # Ref: https://kubernetes.io/docs/user-guide/node-selection/
  nodeSelector: {}
  
  # Whether to use secrets instead of environment values for setting up OAUTH2_PROXY variables
  proxyVarsAsSecrets: true
  
  # Configure Kubernetes liveness and readiness probes.
  # Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
  # Disable both when deploying with Istio 1.0 mTLS. https://istio.io/help/faq/security/#k8s-health-checks
  livenessProbe:
    enabled: true
    initialDelaySeconds: 0
    timeoutSeconds: 1
  
  readinessProbe:
    enabled: true
    initialDelaySeconds: 0
    timeoutSeconds: 5
    periodSeconds: 10
    successThreshold: 1
  
  # Configure Kubernetes security context for container
  # Ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
  securityContext:
    enabled: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
    runAsNonRoot: true
    runAsUser: 2000
    runAsGroup: 2000
    seccompProfile:
      type: RuntimeDefault
  
  deploymentAnnotations: {}
  podAnnotations: {}
  podLabels: {}
  replicaCount: 1
  revisionHistoryLimit: 10
  strategy: {}
  enableServiceLinks: true
  
  ## PodDisruptionBudget settings
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/disruptions/
  podDisruptionBudget:
    enabled: true
    minAvailable: 1
  
  ## Horizontal Pod Autoscaling
  ## ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilizationPercentage: 80
    annotations: {}
  
  # Configure Kubernetes security context for pod
  # Ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
  podSecurityContext: {}
  
  # whether to use http or https
  httpScheme: http
  
  # Configure the session storage type, between cookie and redis
  sessionStorage:
    # Can be one of the supported session storage cookie|redis
    type: cookie
    redis:
      # Name of the Kubernetes secret containing the redis & redis sentinel password values (see also `sessionStorage.redis.passwordKey`)
      existingSecret: ""
      # Redis password value. Applicable for all Redis configurations. Taken from redis subchart secret if not set. `sessionStorage.redis.existingSecret` takes precedence
      password: ""
      # Key of the Kubernetes secret data containing the redis password value. If you use the redis sub chart, make sure
      # this password matches the one used in redis.global.redis.password (see below).
      passwordKey: "redis-password"
      # Can be one of standalone|cluster|sentinel
      clientType: "standalone"
      standalone:
        # URL of redis standalone server for redis session storage (e.g. `redis://HOST[:PORT]`). Automatically generated if not set
        connectionUrl: ""
      cluster:
        # List of Redis cluster connection URLs. Array or single string allowed.
        connectionUrls: []
        # - "redis://127.0.0.1:8000"
        # - "redis://127.0.0.1:8001"
      sentinel:
        # Name of the Kubernetes secret containing the redis sentinel password value (see also `sessionStorage.redis.sentinel.passwordKey`). Default: `sessionStorage.redis.existingSecret`
        existingSecret: ""
        # Redis sentinel password. Used only for sentinel connection; any redis node passwords need to use `sessionStorage.redis.password`
        password: ""
        # Key of the Kubernetes secret data containing the redis sentinel password value
        passwordKey: "redis-sentinel-password"
        # Redis sentinel master name
        masterName: ""
        # List of Redis cluster connection URLs. Array or single string allowed.
        connectionUrls: []
        # - "redis://127.0.0.1:8000"
        # - "redis://127.0.0.1:8001"
  
  # Enables and configure the automatic deployment of the redis subchart
  redis:
    # provision an instance of the redis sub-chart
    enabled: false
    # Redis specific helm chart settings, please see:
    # https://github.com/bitnami/charts/tree/master/bitnami/redis#parameters
    # global:
    #   redis:
    #     password: yourpassword
    # If you install Redis using this sub chart, make sure that the password of the sub chart matches the password
    # you set in sessionStorage.redis.password (see above).
    # redisPort: 6379
    # architecture: standalone
  
  # Enables apiVersion deprecation checks
  checkDeprecation: true
  
  # Allows graceful shutdown
  # terminationGracePeriodSeconds: 65
  # lifecycle:
  #   preStop:
  #     exec:
  #       command: [ "sh", "-c", "sleep 60" ]
  
  metrics:
    # Enable Prometheus metrics endpoint
    enabled: true
    # Serve Prometheus metrics on this port
    port: 44180
    service:
      appProtocol: http
    serviceMonitor:
      enabled: false
      namespace: ""
      # Prometheus Instance definition
      prometheusInstance: default
      # Prometheus scrape interval
      interval: 60s
      # Prometheus scrape timeout
      scrapeTimeout: 30s
      # Add custom labels to the ServiceMonitor resource
      labels: {}
  
      ## scheme: HTTP scheme to use for scraping. Can be used with `tlsConfig` for example if using istio mTLS.
      scheme: ""
  
      ## tlsConfig: TLS configuration to use when scraping the endpoint. For example if using istio mTLS.
      ## Of type: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#tlsconfig
      tlsConfig: {}
  
      ## bearerTokenFile: Path to bearer token file.
      bearerTokenFile: ""
  
      ## Used to pass annotations that are used by the Prometheus installed in your cluster to select Service Monitors to work with
      ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
      annotations: {}
  
      ## Metric relabel configs to apply to samples before ingestion.
      ## [Metric Relabeling](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs)
      metricRelabelings: []
      # - action: keep
      #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'
      #   sourceLabels: [__name__]
  
      ## Relabel configs to apply to samples before ingestion.
      ## [Relabeling](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config)
      relabelings: []
      # - sourceLabels: [__meta_kubernetes_pod_node_name]
      #   separator: ;
      #   regex: ^(.*)$
      #   targetLabel: nodename
      #   replacement: $1
      #   action: replace
